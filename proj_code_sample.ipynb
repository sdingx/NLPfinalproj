{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Final Project\n",
    "Sam Ding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 workers\n"
     ]
    }
   ],
   "source": [
    "# basic data analytics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "# nlp modules\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import multiprocessing\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "import warnings\n",
    "\n",
    "# warnings.simplefilter('once')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "num_processors\n",
    "\n",
    "workers = num_processors-1\n",
    "\n",
    "print(f'Using {workers} workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df_news_final_project = pd.read_parquet('https://storage.googleapis.com/msca-bdp-data-open/news_final_project/news_final_project.parquet', engine='pyarrow')\n",
    "# df_news_final_project.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # zero-shot classification\n",
    "# import torch\n",
    "# from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_final_project = pd.read_csv('sample_600.csv', index_col=0)\n",
    "# df_news_final_project.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>https://www.wkms.org/npr-news/npr-news/2022-10...</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>en</td>\n",
       "      <td>Artificial intelligence could soon diagnose il...</td>\n",
       "      <td>\\n\\nArtificial intelligence could soon diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143316</th>\n",
       "      <td>https://www.wbko.com/prnewswire/2022/08/25/ult...</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>en</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100092</th>\n",
       "      <td>https://www.marketscreener.com/quote/stock/POO...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>en</td>\n",
       "      <td>IN BRIEF: Poolbeg makes \"significant breakthro...</td>\n",
       "      <td>\\n\\nIN BRIEF: Poolbeg makes \"significant break...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url        date   \n",
       "39396   https://www.wkms.org/npr-news/npr-news/2022-10...  2022-10-10  \\\n",
       "143316  https://www.wbko.com/prnewswire/2022/08/25/ult...  2022-08-25   \n",
       "100092  https://www.marketscreener.com/quote/stock/POO...  2022-11-08   \n",
       "\n",
       "       language                                              title   \n",
       "39396        en  Artificial intelligence could soon diagnose il...  \\\n",
       "143316       en  UltraSight Receives CE Mark for Novel Cardiac ...   \n",
       "100092       en  IN BRIEF: Poolbeg makes \"significant breakthro...   \n",
       "\n",
       "                                                     text  \n",
       "39396   \\n\\nArtificial intelligence could soon diagnos...  \n",
       "143316  UltraSight Receives CE Mark for Novel Cardiac ...  \n",
       "100092  \\n\\nIN BRIEF: Poolbeg makes \"significant break...  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_final_project.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up newlines\n",
    "# df_news_final_project['text_clean'] = df_news_final_project['text'].str.replace('\\n', ' ')\n",
    "\n",
    "# clean up tabs\n",
    "df_news_final_project['text_clean'] = df_news_final_project['text'].str.replace('\\t', ' ')\n",
    "\n",
    "# clean up links\n",
    "df_news_final_project['text_clean'] = df_news_final_project['text_clean'].str.replace(r'(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '')\n",
    "\n",
    "# clean up remnants of web crawls\n",
    "df_news_final_project['text_clean'] = df_news_final_project['text_clean'].str.replace(r'&#\\d+;', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "indexlist = []\n",
    "entities = []\n",
    "labels = []\n",
    "\n",
    "docs = nlp.pipe(\n",
    "    df_news_final_project['title'].tolist(),\n",
    "    disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"],\n",
    "    batch_size=200,\n",
    "    n_process=2\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    index = df_news_final_project.index[i]\n",
    "    for ent in doc.ents:\n",
    "        indexlist.append(index)\n",
    "        entities.append(ent.text)\n",
    "        labels.append(ent.label_)\n",
    "\n",
    "\n",
    "ner_df = pd.DataFrame({\"Index\": indexlist, \"Entities\":entities,'Labels':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143316</td>\n",
       "      <td>UltraSight</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143316</td>\n",
       "      <td>CE Mark</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102690</td>\n",
       "      <td>Square Peg</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102690</td>\n",
       "      <td>AI</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21501</td>\n",
       "      <td>1.04</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>9710</td>\n",
       "      <td>Artificial Intelligence and Machine Learning</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>45140</td>\n",
       "      <td>Hexaware Collaborate to</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>45140</td>\n",
       "      <td>Help Customers Accelerate</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>45140</td>\n",
       "      <td>Journey</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>150157</td>\n",
       "      <td>KU</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                      Entities    Labels\n",
       "0     143316                                    UltraSight       ORG\n",
       "1     143316                                       CE Mark    PERSON\n",
       "2     102690                                    Square Peg    PERSON\n",
       "3     102690                                            AI       ORG\n",
       "4      21501                                          1.04  CARDINAL\n",
       "...      ...                                           ...       ...\n",
       "1333    9710  Artificial Intelligence and Machine Learning       ORG\n",
       "1334   45140                       Hexaware Collaborate to       ORG\n",
       "1335   45140                     Help Customers Accelerate       ORG\n",
       "1336   45140                                       Journey   PRODUCT\n",
       "1337  150157                                            KU   PRODUCT\n",
       "\n",
       "[1338 rows x 3 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39396     Artificial intelligence could soon diagnose il...\n",
       "100092    IN BRIEF: Poolbeg makes \"significant breakthro...\n",
       "21501     Patch 1.04: A Wagonload of AI · Grand Tacticia...\n",
       "83882     Mohammad Hosseini: Should we bring AI into hos...\n",
       "151392    SHUTTERSTOCK PARTNERS WITH OPENAI AND LEADS TH...\n",
       "                                ...                        \n",
       "9820          Artificial Intelligence Wish List - NewsBreak\n",
       "119656    Rockies' trade deadline: Trevor Story, Jon Gra...\n",
       "129684    Can ChatGPT help with investments if you want ...\n",
       "117860    BuzzFeed to use artificial intelligence for co...\n",
       "150157    How the KU community feels about ChatGPT and w...\n",
       "Name: title, Length: 171, dtype: object"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find indexes where labels have no ORG\n",
    "\n",
    "with_org_list = list(ner_df[ner_df['Labels'] == 'ORG']['Index'].unique())\n",
    "\n",
    "no_org_list = list(set(df_news_final_project.index) - set(with_org_list))\n",
    "\n",
    "# get the title for those indexes\n",
    "\n",
    "df_news_final_project[df_news_final_project.index.isin(no_org_list)]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39396</th>\n",
       "      <td>https://www.wkms.org/npr-news/npr-news/2022-10...</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>en</td>\n",
       "      <td>Artificial intelligence could soon diagnose il...</td>\n",
       "      <td>\\n\\nArtificial intelligence could soon diagnos...</td>\n",
       "      <td>\\n\\nArtificial intelligence could soon diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143316</th>\n",
       "      <td>https://www.wbko.com/prnewswire/2022/08/25/ult...</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>en</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url        date   \n",
       "39396   https://www.wkms.org/npr-news/npr-news/2022-10...  2022-10-10  \\\n",
       "143316  https://www.wbko.com/prnewswire/2022/08/25/ult...  2022-08-25   \n",
       "\n",
       "       language                                              title   \n",
       "39396        en  Artificial intelligence could soon diagnose il...  \\\n",
       "143316       en  UltraSight Receives CE Mark for Novel Cardiac ...   \n",
       "\n",
       "                                                     text   \n",
       "39396   \\n\\nArtificial intelligence could soon diagnos...  \\\n",
       "143316  UltraSight Receives CE Mark for Novel Cardiac ...   \n",
       "\n",
       "                                               text_clean  \n",
       "39396   \\n\\nArtificial intelligence could soon diagnos...  \n",
       "143316  UltraSight Receives CE Mark for Novel Cardiac ...  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_final_project.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "notitle = []\n",
    "for i in df_news_final_project.index.values:\n",
    "    notitle.append(df_news_final_project['text_clean'][i].replace(df_news_final_project['title'][i], 'Hahahah 23, 2026')) # replace by this chunk so title can also be split by pattern\n",
    "\n",
    "df_news_final_project['text_notitle'] = notitle\n",
    "\n",
    "# drop everything after string 'for more information'ABC\n",
    "\n",
    "df_news_final_project['text_notitle'] = df_news_final_project['text_notitle'].str.split(r'[F|f]or more information', expand=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(\\w{3,10}\\.*\\s\\d{1,2}\\,*\\s20\\d{2})|(\\d{1,2}\\s\\w{3,10}\\.*\\s20\\d{2})|\\n+'\n",
    "\n",
    "df_news_final_project['split'] = df_news_final_project['text_notitle'].apply(lambda x: re.split(pattern=pattern, string=x))\n",
    "df_news_final_project['split_len'] = df_news_final_project['split'].apply(lambda x: len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len 1 was 116, after new pattern 78, after new pattern all splitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_most_similar(index):\n",
    "    '''\n",
    "    This function takes in an index of the dataframe and returns the most similar text to the title,\n",
    "    filtering out other unnecessary texts.\n",
    "    '''\n",
    "\n",
    "    title = df_news_final_project['title'][index]\n",
    "    texts = df_news_final_project['split'][index]\n",
    "\n",
    "    # print('Original:\\n', texts)\n",
    "\n",
    "    # compare capital letters and periods, drop if there are more capital letters in the texts\n",
    "    texts = [x for x in texts if x != None]\n",
    "\n",
    "    # print('Dropping None:\\n', texts)\n",
    "\n",
    "    # print('Dropping more period than capital:\\n', texts)\n",
    "\n",
    "    # take out texts that are too short\n",
    "    texts = [x for x in texts if len(x) > 150]\n",
    "\n",
    "    # print('Dropping too short:\\n', texts)\n",
    "\n",
    "    # drop texts with Tab patterns\n",
    "    pattern = r'([A-Z][a-z]+(\\n|\\t)+){4}'\n",
    "    texts =  [re.sub(pattern, '', x) for x in texts]\n",
    "\n",
    "    # print('Dropping Tab patterns:\\n', texts)\n",
    "\n",
    "    # keep texts with small letter patterns\n",
    "    pattern = r'([a-z]+\\s){4}'\n",
    "    texts = [x for x in texts if re.search(pattern, x) != None]\n",
    "\n",
    "    # print('Keeping small letter patterns:\\n', texts)\n",
    "\n",
    "\n",
    "    # return NA if there are no text splits left\n",
    "    if len(texts) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Tokenize the title and texts\n",
    "    tokenized_title = nltk.word_tokenize(title.lower())\n",
    "    tokenized_texts = [nltk.word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # Convert the tokenized texts to strings\n",
    "    text_strings = [' '.join(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "    # print('Tokenized texts:\\n', len(text_strings))\n",
    "\n",
    "    index_to_return = 0\n",
    "\n",
    "    # Create a TF-IDF vectorizer and fit it to the text strings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_strings)\n",
    "        # print(tfidf_matrix.shape)\n",
    "\n",
    "    # Compute the cosine similarity between the title and each text\n",
    "    title_vector = vectorizer.transform([' '.join(tokenized_title)])\n",
    "    similarity_scores = cosine_similarity(title_vector, tfidf_matrix)\n",
    "\n",
    "    most_similar_index = similarity_scores.argmax()\n",
    "        \n",
    "    most_similar_score = similarity_scores.max()\n",
    "    index_to_return = most_similar_index\n",
    "        \n",
    "    list_articles = []\n",
    "    list_scores = []\n",
    "\n",
    "    for i in range(0,len(similarity_scores[0])):\n",
    "        if similarity_scores[0][i] >= 0.07:\n",
    "            list_articles.append(text_strings[i])\n",
    "            list_scores.append(similarity_scores[0][i])\n",
    "        # print(len(text_strings), len(similarity_scores[0]))\n",
    "                \n",
    "        # if len(text_strings) > 1:\n",
    "        #     second_most_similar_index = similarity_scores.argsort()[0][-2]\n",
    "        #     # print(similarity_scores)\n",
    "        #     second_most_similar_score = similarity_scores[0][second_most_similar_index]\n",
    "        #     if most_similar_score > 0.2:\n",
    "        #         index_to_return = second_most_similar_index\n",
    "        # # return texts[index_to_return]\n",
    "        # return \n",
    "\n",
    "    # except:\n",
    "    #     pass\n",
    "    \n",
    "\n",
    "    return ' '.join(list_articles)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 9)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar = []\n",
    "\n",
    "for i in df_news_final_project.index.values:\n",
    "    most_similar.append(get_most_similar(i))\n",
    "\n",
    "df_news_final_project['text_clean'] = most_similar\n",
    "\n",
    "df_news_final_project.dropna(subset=['text_clean'], inplace=True)\n",
    "\n",
    "df_news_final_project.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/12 13:15:28 WARN TaskSetManager: Stage 20 contains a task of very large size (2334 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import StopWordsCleaner, Tokenizer\n",
    "import sparknlp\n",
    "\n",
    "# start Spark session\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# create Spark dataframe\n",
    "df_spark = spark.createDataFrame(df_news_final_project)\n",
    "\n",
    "# define a UDF that detects if the article has keywords\n",
    "keywords = ['artificial intelligence', 'machine learning', 'data science', 'data analytics']\n",
    "\n",
    "def has_keywords(text):\n",
    "    for keyword in keywords:\n",
    "        if keyword in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "has_keywords_udf = udf(has_keywords)\n",
    "\n",
    "# add a column to the dataframe that indicates if the article has keywords\n",
    "df_spark = df_spark.withColumn('has_keywords', has_keywords_udf(df_spark['text_clean']))\n",
    "\n",
    "# drop articles that do not have keywords\n",
    "df_spark = df_spark.filter(df_spark['has_keywords'] == True)\n",
    "\n",
    "# make df_spark the new df_news_final_project\n",
    "df_news_final_project = df_spark.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_news_final_project['text_clean'].apply(lambda x: x.find('apple')).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_notitle</th>\n",
       "      <th>split</th>\n",
       "      <th>split_len</th>\n",
       "      <th>has_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.wbko.com/prnewswire/2022/08/25/ult...</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>en</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "      <td>UltraSight Receives CE Mark for Novel Cardiac ...</td>\n",
       "      <td>at 7:30 am cdt|updated : 1 hour agolandmark ac...</td>\n",
       "      <td>Hahahah 23, 2026\\n\\nSkip to contentNewsWeather...</td>\n",
       "      <td>[, Hahahah 23, 2026, None, , None, None, Skip ...</td>\n",
       "      <td>16</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.marketscreener.com/quote/stock/POO...</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>en</td>\n",
       "      <td>IN BRIEF: Poolbeg makes \"significant breakthro...</td>\n",
       "      <td>\\n\\nIN BRIEF: Poolbeg makes \"significant break...</td>\n",
       "      <td>poolbeg pharma plc - london-based clinical sta...</td>\n",
       "      <td>\\n\\nHahahah 23, 2026\\n \\n\\n                   ...</td>\n",
       "      <td>[, None, None, , Hahahah 23, 2026, None, , Non...</td>\n",
       "      <td>745</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.brisbanetimes.com.au/business/smal...</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>en</td>\n",
       "      <td>Square Peg aims for the AI sweet spot with lat...</td>\n",
       "      <td>Square Peg aims for the AI sweet spot with lat...</td>\n",
       "      <td>— 9.00pmsavelog in , register or subscribe to ...</td>\n",
       "      <td>Hahahah 23, 2026Hahahah 23, 2026Skip to sectio...</td>\n",
       "      <td>[, Hahahah 23, 2026, None, , Hahahah 23, 2026,...</td>\n",
       "      <td>13</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://forextv.com/top-news/forgerock-powers-...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>en</td>\n",
       "      <td>ForgeRock Powers New Era of Digital Identity w...</td>\n",
       "      <td>\\n\\nForgeRock Powers New Era of Digital Identi...</td>\n",
       "      <td>( globe newswire ) — forgerock® , the leading ...</td>\n",
       "      <td>\\n\\nHahahah 23, 2026\\n\\n \\n\\n \\n\\nBreaking New...</td>\n",
       "      <td>[, None, None, , Hahahah 23, 2026, None, , Non...</td>\n",
       "      <td>295</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pantagraph.com/opinion/columnists/moha...</td>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>en</td>\n",
       "      <td>Mohammad Hosseini: Should we bring AI into hos...</td>\n",
       "      <td>\\nMohammad Hosseini: Should we bring AI into h...</td>\n",
       "      <td>recently , two major news stories in the techn...</td>\n",
       "      <td>\\nHahahah 23, 2026\\n\\nSkip to main contentSkip...</td>\n",
       "      <td>[, None, None, , Hahahah 23, 2026, None, , Non...</td>\n",
       "      <td>865</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>https://www.kshb.com/news/national/buzzfeed-to...</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>en</td>\n",
       "      <td>BuzzFeed to use artificial intelligence for co...</td>\n",
       "      <td>\\nBuzzFeed to use artificial intelligence for ...</td>\n",
       "      <td>file photo shows the entrance to buzzfeed in n...</td>\n",
       "      <td>\\nHahahah 23, 2026\\n1 weather alerts\\n1 closin...</td>\n",
       "      <td>[, None, None, , Hahahah 23, 2026, None, , Non...</td>\n",
       "      <td>628</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>https://www.einpresswire.com/article/614170798...</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>en</td>\n",
       "      <td>EMERGE Consortium awarded grant by European...</td>\n",
       "      <td>\\n  EMERGE Consortium awarded grant by Europea...</td>\n",
       "      <td>project scored first in the eic ’ s pathfinder...</td>\n",
       "      <td>\\n  EMERGE Consortium awarded grant by Europea...</td>\n",
       "      <td>[, None, None,   EMERGE Consortium awarded gra...</td>\n",
       "      <td>1573</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>https://www.kktv.com/prnewswire/2021/10/28/pin...</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>en</td>\n",
       "      <td>Pinecone Recognized as a 2021 Gartner® Cool Ve...</td>\n",
       "      <td>Pinecone Recognized as a 2021 Gartner® Cool Ve...</td>\n",
       "      <td>/prnewswire/ -- pinecone systems inc. , a mach...</td>\n",
       "      <td>Hahahah 23, 2026\\n\\nSkip to contentNewsWeather...</td>\n",
       "      <td>[, Hahahah 23, 2026, None, , None, None, Skip ...</td>\n",
       "      <td>19</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>https://www.live5news.com/prnewswire/2021/11/2...</td>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>en</td>\n",
       "      <td>DataRobot and Hexaware Collaborate to Help Cus...</td>\n",
       "      <td>DataRobot and Hexaware Collaborate to Help Cus...</td>\n",
       "      <td>/prnewswire/ -- hexaware , a global informatio...</td>\n",
       "      <td>Hahahah 23, 2026\\n\\nSkip to contentSC LotteryL...</td>\n",
       "      <td>[, Hahahah 23, 2026, None, , None, None, Skip ...</td>\n",
       "      <td>16</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>https://www.kansan.com/news/how-the-ku-communi...</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>en</td>\n",
       "      <td>How the KU community feels about ChatGPT and w...</td>\n",
       "      <td>\\nHow the KU community feels about ChatGPT and...</td>\n",
       "      <td>dr. genelle belmas , journalism professor spec...</td>\n",
       "      <td>\\nHahahah 23, 2026\\nSkip to main content\\nYou ...</td>\n",
       "      <td>[, None, None, , Hahahah 23, 2026, None, , Non...</td>\n",
       "      <td>532</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url        date language   \n",
       "0    https://www.wbko.com/prnewswire/2022/08/25/ult...  2022-08-25       en  \\\n",
       "1    https://www.marketscreener.com/quote/stock/POO...  2022-11-08       en   \n",
       "2    https://www.brisbanetimes.com.au/business/smal...  2020-10-27       en   \n",
       "3    https://forextv.com/top-news/forgerock-powers-...  2020-06-23       en   \n",
       "4    https://pantagraph.com/opinion/columnists/moha...  2023-04-14       en   \n",
       "..                                                 ...         ...      ...   \n",
       "384  https://www.kshb.com/news/national/buzzfeed-to...  2023-01-30       en   \n",
       "385  https://www.einpresswire.com/article/614170798...  2023-01-31       en   \n",
       "386  https://www.kktv.com/prnewswire/2021/10/28/pin...  2021-10-28       en   \n",
       "387  https://www.live5news.com/prnewswire/2021/11/2...  2021-11-24       en   \n",
       "388  https://www.kansan.com/news/how-the-ku-communi...  2023-02-27       en   \n",
       "\n",
       "                                                 title   \n",
       "0    UltraSight Receives CE Mark for Novel Cardiac ...  \\\n",
       "1    IN BRIEF: Poolbeg makes \"significant breakthro...   \n",
       "2    Square Peg aims for the AI sweet spot with lat...   \n",
       "3    ForgeRock Powers New Era of Digital Identity w...   \n",
       "4    Mohammad Hosseini: Should we bring AI into hos...   \n",
       "..                                                 ...   \n",
       "384  BuzzFeed to use artificial intelligence for co...   \n",
       "385     EMERGE Consortium awarded grant by European...   \n",
       "386  Pinecone Recognized as a 2021 Gartner® Cool Ve...   \n",
       "387  DataRobot and Hexaware Collaborate to Help Cus...   \n",
       "388  How the KU community feels about ChatGPT and w...   \n",
       "\n",
       "                                                  text   \n",
       "0    UltraSight Receives CE Mark for Novel Cardiac ...  \\\n",
       "1    \\n\\nIN BRIEF: Poolbeg makes \"significant break...   \n",
       "2    Square Peg aims for the AI sweet spot with lat...   \n",
       "3    \\n\\nForgeRock Powers New Era of Digital Identi...   \n",
       "4    \\nMohammad Hosseini: Should we bring AI into h...   \n",
       "..                                                 ...   \n",
       "384  \\nBuzzFeed to use artificial intelligence for ...   \n",
       "385  \\n  EMERGE Consortium awarded grant by Europea...   \n",
       "386  Pinecone Recognized as a 2021 Gartner® Cool Ve...   \n",
       "387  DataRobot and Hexaware Collaborate to Help Cus...   \n",
       "388  \\nHow the KU community feels about ChatGPT and...   \n",
       "\n",
       "                                            text_clean   \n",
       "0    at 7:30 am cdt|updated : 1 hour agolandmark ac...  \\\n",
       "1    poolbeg pharma plc - london-based clinical sta...   \n",
       "2    — 9.00pmsavelog in , register or subscribe to ...   \n",
       "3    ( globe newswire ) — forgerock® , the leading ...   \n",
       "4    recently , two major news stories in the techn...   \n",
       "..                                                 ...   \n",
       "384  file photo shows the entrance to buzzfeed in n...   \n",
       "385  project scored first in the eic ’ s pathfinder...   \n",
       "386  /prnewswire/ -- pinecone systems inc. , a mach...   \n",
       "387  /prnewswire/ -- hexaware , a global informatio...   \n",
       "388  dr. genelle belmas , journalism professor spec...   \n",
       "\n",
       "                                          text_notitle   \n",
       "0    Hahahah 23, 2026\\n\\nSkip to contentNewsWeather...  \\\n",
       "1    \\n\\nHahahah 23, 2026\\n \\n\\n                   ...   \n",
       "2    Hahahah 23, 2026Hahahah 23, 2026Skip to sectio...   \n",
       "3    \\n\\nHahahah 23, 2026\\n\\n \\n\\n \\n\\nBreaking New...   \n",
       "4    \\nHahahah 23, 2026\\n\\nSkip to main contentSkip...   \n",
       "..                                                 ...   \n",
       "384  \\nHahahah 23, 2026\\n1 weather alerts\\n1 closin...   \n",
       "385  \\n  EMERGE Consortium awarded grant by Europea...   \n",
       "386  Hahahah 23, 2026\\n\\nSkip to contentNewsWeather...   \n",
       "387  Hahahah 23, 2026\\n\\nSkip to contentSC LotteryL...   \n",
       "388  \\nHahahah 23, 2026\\nSkip to main content\\nYou ...   \n",
       "\n",
       "                                                 split  split_len has_keywords  \n",
       "0    [, Hahahah 23, 2026, None, , None, None, Skip ...         16         true  \n",
       "1    [, None, None, , Hahahah 23, 2026, None, , Non...        745         true  \n",
       "2    [, Hahahah 23, 2026, None, , Hahahah 23, 2026,...         13         true  \n",
       "3    [, None, None, , Hahahah 23, 2026, None, , Non...        295         true  \n",
       "4    [, None, None, , Hahahah 23, 2026, None, , Non...        865         true  \n",
       "..                                                 ...        ...          ...  \n",
       "384  [, None, None, , Hahahah 23, 2026, None, , Non...        628         true  \n",
       "385  [, None, None,   EMERGE Consortium awarded gra...       1573         true  \n",
       "386  [, Hahahah 23, 2026, None, , None, None, Skip ...         19         true  \n",
       "387  [, Hahahah 23, 2026, None, , None, None, Skip ...         16         true  \n",
       "388  [, None, None, , Hahahah 23, 2026, None, , Non...        532         true  \n",
       "\n",
       "[389 rows x 10 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the cleaned text for downstream analysis. Currently there are 587 documents that are not null and have the mentions of those words in Data Science."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news_final_project.iloc[:150][['title', 'text_clean']].to_csv('sentanalysis150.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arize AI Announces SOC 2 Type II Certification\n",
      "\n",
      "Skip to contentLIVENewsSportsWeatherInterviewsShop LocalNow HiringSearchHomeLIVENews 4 - LIVELatest NewscastsNews 4 SpecialsProgramming ScheduleRequest a Copy of a News StoryNewsAlabamaFloridaGeorgiaNationalAbsolutely AlabamaSEE it --> SEND itWeatherTracking the TropicsInteractive RadarWeather Map RoomClosingsColor The WeatherSportsSports ScoreboardFNF ScoreboardFriday Night FootballCommunityCommunity CalendarWiregrass PhotobookMr. FoodWeekly SegmentsMobility MondayLegal TalkFeaturesSilent Heroes Of The WiregrassLiving 4 LocalContestsAbout UsMeet the WTVY News TeamAdvertise with WTVYDownload Our AppsInterviewsNewsletterJobs at WTVYCBSNBCMeTVThe CWFull Court Press with Greta Van SusterenCircle - Country Music & LifestyleGray DC BureauInvestigate TVPowerNationLatest NewscastsPress ReleasesArize AI Announces SOC 2 Type II CertificationPublished: Apr. 21, 2022 at 10:00 AM CDT|Updated: 58 minutes agoBERKELEY, Calif., April 21, 2022 /PRNewswire/ -- Arize AI, a leading ML observability company, today announced that the company achieved SOC 2 Type II certification under standards set by the American Institute of Certified Public Accountants (AICPA). SOC 2 (System and Organization Controls) requires a third-party audit that analyzes key criteria such as organization and management, communication, risk assessment, select controls, monitoring controls, system operations, and more.Arize AI (PRNewsfoto/Arize AI)(PRNewswire)Arize's Foundation Of Security, Availability, and Privacy Arize's SOC 2 security certification validates that the company has adequate processes and policies to securely handle both customer and organizational data. With a third-party-vetted security program in place, users can confidently use the Arize platform knowing their data is safe and secure.The ability to dependably handle organizational and customer data starts with processes and policies that Arize has implemented to ensure security is both operationalized and always top of mind. Arize's security strategy pillars include:Business Continuity Plan - Sets safeguards to ensure Arize is prepared to provide its services regardless of circumstanceMobile Device Management - Ensures all Arize devices are controlled and securedSecure Development Lifecycle - Guarantees the highest quality security guidelines to Arize's development process and minimizes the number of vulnerabilities within Arize's softwareEncryption Policies - Secure data at REST and in transit by using the most modern encryption algorithmsThis certification comes on the heels of the company's recent debut of its self-serve ML observability platform, which already tracks hundreds of billions of predictions a month on behalf of large enterprises and disruptive startups.\"Our SOC2 Certification is a validation of Arize AI's security strategy, but it's really just the beginning,\" said Remi Cattiau, Chief Information Security Officer at Arize AI. \"Realizing Arize's mission of making AI work and work for the people necessarily starts with putting security and privacy at the heart of everything we do.\"To request a copy of the report, please contact us here.About Arize AIArize AI is a Machine Learning Observability platform that helps ML practitioners successfully take models from research to production with ease. Arize's automated model monitoring and analytics platform help ML teams quickly detect issues when they emerge, troubleshoot why they happened, and improve overall model performance. By connecting offline training and validation datasets to online production data in a central inference store, ML teams can streamline model validation, drift detection, data quality checks, and model performance management.Arize AI acts as the guardrail on deployed AI, providing transparency and introspection into historically black box systems to ensure more effective and responsible AI. To learn more about Arize or machine learning observability and monitoring, visit our blog and resource hub.Media Contact: Krystal Kirkland, press@arize.comView original content to download multimedia:https://www.prnewswire.com/news-releases/arize-ai-announces-soc-2-type-ii-certification-301529874.htmlSOURCE  Arize AIThe above press release was provided courtesy of PRNewswire. The views, opinions and statements in the press release are not endorsed by Gray Media Group nor do they necessarily state or reflect those of Gray Media Group, Inc.NewsWeatherSportsCommunityWTVY285 N Foster StreetDothan, AL 36303(334) 792-3195Public Inspection Filemgr@wtvy.com - (334) 792-3195Terms of ServicePrivacy PolicyFCC ApplicationsEEO StatementAdvertisingA Gray Media Group, Inc. Station - ©  2002-2022 Gray Television, Inc.\n"
     ]
    }
   ],
   "source": [
    "print(df_news_final_project.iloc[149]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
